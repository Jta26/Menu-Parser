[
        {
            "title": "Capstone Blog Creation",
            "date": "Jan 11 2019",
            "week": "1",
            "paragraphs": [
                "Today I created this single page blog. In total it took about 10 hours to create, an utlizes Next.js and React to an interactive webpage without the need to make multiple requests to a server hosted on an AWS instance running Ubuntu 18.04.  React is a javascript front-end framework used to make creating interactive content online simple and modular. The blog selection bar, and blog content is pulled from a JSON file on the server, that is to be manually updated when I make a new blog post. The choice to program my own blog instead of using a service like wordpress is to exmplify my front-end development ability. My capstone project is going to involve all facets of full-stack development, including data retrieve and organization scripts, databases, RESTful API back-end technologies, and front-end development frameworks such as React.\nAll images in this blog will be at the bottom of the blog post. They are all clickable such that they can be viewed in a lightbox. The blogs will be added on the left side of the page as I progress through my capstone project. This website is not made to be mobile-oreiented."
            ],
            "images": [
                { "src": "https://i.imgur.com/gTvLu4t.png", "width": 2, "height": 1 },
                { "src": "https://i.imgur.com/U4QZeGh.png", "width": 1.5, "height": 1 },
                { "src": "https://i.imgur.com/GqV2Vh5.png", "width": 2, "height": 1 }                
            ]
        },
        {
            "title": "Database and Python Script Created",
            "date": "Jan 19 2019",
            "week": "2",
            "paragraphs": [
                "This week I developed a Python script that downloads, reads, and parses the .pdf files found at any given location. The script uses BeautifulSoup, Pandas, Numpy, and a vareity of other packages. The pdf file locations are discovered using a regular expression that finds .pdf urls in html. Those urls are then downloaded directly and saved to a directory. A package called Tabula pareses the downloaded PDF files for tables and converts them into dataframes that are readable by Pandas. The dataframes are then seperated into columns of data. The columns are searched for a readable date such as “12-Jan” and that is converted to a Python datetime readable format.\n The columns that contain the menu items are then organized by date and sent to a seperate method that uploads them to a MySql Database. The MySql database is hosted on AWS RDS and is designed in Third Normal Form. Below there is an Entity Relationship Diagram, as well as a Logical Model of the Database.    "
            ],
            "images": [
                { "src": "https://i.imgur.com/ZJtIoS2.png", "width": 2, "height": 1 },
                { "src": "https://i.imgur.com/Oql4TTv.png", "width": 1.2, "height": 1 },
                { "src": "https://i.imgur.com/chPYKbf.png", "width": 1.4, "height": 1 },
                { "src": "https://i.imgur.com/ItVio5v.png", "width": 1.4, "height": 1 },
                {"src": "https://i.ibb.co/bFL3M0j/Screenshot-from-2019-01-20-16-53-48.png", "width": 1.4, "height": 1}   
                
            ]
        }
        
]
